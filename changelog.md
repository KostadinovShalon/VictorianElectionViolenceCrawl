# Change Log

All notable changes since version 1.28.1 are documented in this file.

The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/)
and this project adheres to [Semantic Versioning](http://semver.org/spec/v2.0.0.html).

## [1.31.0] - 2019-03-04
### Changed
- Several changes were done in the code. These changes don't directly affect the performance, but they are useful
maintenance
- Spider settings: now only one concurrent item
- PageItem class now holds information of only one article. The "yield" clause was changed to the standard use in 
the parse function
- Items were moved to items.py
- In general, code was cleaned from previous developers

### Added
- **Count mode**. This mode is used to count how many articles are in a search
- **Split option**. This options allows the user to split a search in several searches split by 
several time intervals. This option is compatible with the recovery mode (although it is still experimental)

## [1.30.2] - 2018-11-26
### Changed
- The script ocr_updater.py was modified to allow candidate id selection

## [1.30.1] - 2018-11-22
### Fixed
- OCR was not being uploaded to the DB for new Candidate Documents

## [1.30.0] - 2018-10-26
### Changed
- Searchs are inserted in the database after performing the first search. In previous versions, 
searchs were inserted into the database at the beginning of the spider, at the same time.

### Added
- **Recovery mode**. A new mode to continue crawling in the last page crawled by the spider. This
avoids having to crawl again pages already processed.   

## [1.29.5] - 2018-09-18
### Changed
- Field *title* from PortalDocument is now not used.

## [1.29.4] - 2018-08-17
### Changed
- Candidate documents are created when doing the crawl. Script generate_candidates only generates the CSV.

## [1.29.3] - 2018-08-16
### Changed
- Default values for g_status and status_writer are status and 'gary'.
### Fixed
- generate_candidates.py did not insert candidate documents because g_status and status_writer were not defined.

## [1.29.2] - 2018-08-16
### Changed
- CSV for candidate documents was reformatted. Added g_status and status_writer columns

## [1.29.1] - 2018-08-14
### Fixed
- When portal document files failed to be uploaded to the server, their candidate status was not updated.

## [1.29.0] - 2018-08-12
### Added
- A generate_candidates.py script was added to get candidate documents after a crawl
- An *slow* option to retry the downloading of candidate files
- Searches are cached for one hour
- User agents are randomly selected for each crawl

### Changed
- The update_pdf_files.py script keeps running if a document fails
- The spiders do not generate the csv with the candidate documents anymore. This step was causing the crawler to slow down dramatically after a few pages (barely 1 page/min). 
Now, with this change, at least a speed of 14 pages/min was achieved in fast mode (a faster crawl may be achieved by changing the DOWNLOAD_DELAY parameter in settings.py).
To get the candidate documents related with a search, the generate_candidates.py script is provided.
- SQLAlchemy session is now global.
- Article pdfs are now generated with absolute coordinates and not in a column fashion (see document 1281)

### Fixed
- Some portal document pdfs could not been downloaded.

## [1.28.3] - 2018-08-10
### Added
- Advanced search parameters are stored in the database

### Fixed
- Some candidate documents could not be uploaded into the database because their 'article_title' field

## [1.28.2] - 2018-08-07
### Changed
- Dates from the advanced search xlsx file are now formatted as text (date must use the format yyyy-mm-dd)
- JSON files are not generated by default. If a JSON file has to be generated, use generate_json=true
- Slow mode runs without generating the JSON

## [1.28.1] - 2018-08-06
### Added
- Fast mode operation (no OCRs are downloaded)
- A new script called ocr_updater was added to download the OCR of those files crawled in fast mode
- The option of generating the JSON file (only in fast mode)
- Advanced search added. An XLSX file is provided to define the search terms
- Documentation is provided in the [README.md](/README.md) file

### Changed
- Complementary scripts like update_pdf_files.py were moved to the root folder. *Tools* folder was removed
- *openpyxl 2.5.5 was added to the requirements*
